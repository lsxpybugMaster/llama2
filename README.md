## ğŸ¦™ LLaMA2
* llama2 code from scratch
* æ„å»ºçš„æ˜¯llama-2-7B åŸå§‹æ¨¡å‹

## ğŸ“¦ï¸ æƒé‡æ–‡ä»¶ä¸‹è½½
* https://www.modelscope.cn/models/angelala00/Llama-2-7b/files
* æ ¹ç›®å½•ä¸‹åˆ›å»ºæ–‡ä»¶å¤¹`llama-2-7b`
* ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶è‡³å…¶ä¸­,å¾—åˆ°æ–‡ä»¶ç»“æ„ï¼š

```
llama-2-7b/
â”œâ”€â”€ consolidated.00.pth
â”œâ”€â”€ params.json
â””â”€â”€ tokenizer.model
```

## ğŸ¤— è¿è¡Œ
* `z_Llama2.ipynb`ä»…ç”¨ä½œç¬”è®°,ä¸å»ºè®®ç›´æ¥è¿è¡Œ
* ç›´æ¥è¿è¡Œ`inference.py`å³å¯
* `inference.py`ä¸­ä¿®æ”¹promptçš„ä½ç½®:

```python
if __name__ == '__main__':  
    torch.manual_seed(0)
    allow_cuda = False
    device = 'cuda' if torch.cuda.is_available() and allow_cuda else 'cpu'
    ### ä¿®æ”¹promptså†…å®¹å³å¯
    prompts = [
        "Simply put, the theory of relativity states that ",
        
        "If Google was an Italian company founded in Milan, it would",
    ]
```
